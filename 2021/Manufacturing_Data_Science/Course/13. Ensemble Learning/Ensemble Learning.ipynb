{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "0. 簡言\n",
    "1. Bagging\n",
    "2. Boosting\n",
    "3. Stacking\n",
    "4. 總結\n",
    "5. Reference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 簡言\n",
    "\n",
    "近幾年來，Ensemble Learning(集成學習)幾乎是火熱地襲捲而來。\n",
    "\n",
    "無論是在 Kaggle 上的各種競賽、或是全世界(包括台灣)各企業舉辦的比賽，只要是牽扯到「預測」或「分類」的問題，在不考慮變數解釋的狀況下，如果不套入 Ensemble Learning 的技巧，就無法獲得很好的名次。\n",
    "\n",
    "例如，現在 Kaggle 上世界排名第一的 [Giba](https://www.kaggle.com/titericz) ，就曾在 2015 年由 Otto 舉辦的比賽中，使用了 38 個模型，搭配 Feature Engineering 以及 Stacking 的技巧，建立三層(1st level: 33 models; 2nd level: 3rd level: composed weights) 的預測架構，並獲得第一名，相當精彩且值得參考：[1st PLACE - WINNER SOLUTION - Gilberto Titericz & Stanislav Semenov](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335)\n",
    "\n",
    "此外，由美國最大問答論壇 Quora 舉辦的問題配對比賽中，當時第一名的 [Maximilien@DAMI](https://www.kaggle.com/colonelcarotte) 也分享他的建模心得：在使用一般經典的類神經網路下，結合 Stacking 的技巧，建構出四層的文字比對架構：[Quora Question Pairs 競賽冠軍經驗分享：採用 4 層堆疊，經典模型比較給力](http://bangqu.com/12Ks1D.html)\n",
    "\n",
    "所謂的 Ensemble Learning ，其實就是「三個臭皮匠，勝過一個諸葛亮」的概念，希望藉由團隊合作，結合多種模型的表現，提升最後的預測/分類結果。一般有三種常見的架構：\n",
    "\n",
    "Bagging (Bootstrap aggregating)\n",
    "\n",
    "Boosting\n",
    "\n",
    "Stacking (short for [stacked generalization](http://machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf), also called meta ensembling)\n",
    "\n",
    "這三種架構在結合模型時使用的概念並不一樣，因此本文中會依序介紹這三種方法的概念與實踐方式(用 Python)，並示範基於此概念而衍生出來的模型程式如何撰寫： Random Forest(隨機森林) 跟 Gradient Boosting Machine (梯度推進器)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料\n",
    "\n",
    "這裡拿的是機台預測壽命的資料，是 IEEE PHM 2012 Prognostic challenge 的資料，可以從https://ti.arc.nasa.gov/c/13/. 下載，其中包含了三個機台設定值及 21 個 sensor 收集的資料，從初始狀態記錄到機台損壞全部有218個引擎，從開始運作直到毀損的時間序列（每個引擎的初始狀態與操作條件有所不同），其中每個多元時間序列包含了3 個操作設定與21 個感測量測值。\n",
    "\n",
    "要注意的是，依變數會是 RUL(Remain useful life)，主要是從每個機台 (id) 最大的cycle回推而來的，代表還有幾個cycle可以存活，自變數則是當下的時間(cycle)，及不同的感測量測值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"train.txt\",header=None,sep=' ')\n",
    "df = df.drop([26, 27], axis=1)\n",
    "df.columns = ['id','cycle','setting1','setting2','setting3','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0047</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>20.0</td>\n",
       "      <td>489.05</td>\n",
       "      <td>604.13</td>\n",
       "      <td>1499.45</td>\n",
       "      <td>1309.95</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>372.15</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>8120.83</td>\n",
       "      <td>8.6216</td>\n",
       "      <td>0.03</td>\n",
       "      <td>368</td>\n",
       "      <td>2319</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>17.1735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.13</td>\n",
       "      <td>1584.55</td>\n",
       "      <td>1403.96</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.81</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8132.87</td>\n",
       "      <td>8.3907</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.3619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.9986</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>60.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.42</td>\n",
       "      <td>1368.17</td>\n",
       "      <td>1122.49</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>183.26</td>\n",
       "      <td>2387.95</td>\n",
       "      <td>8063.84</td>\n",
       "      <td>9.3557</td>\n",
       "      <td>0.02</td>\n",
       "      <td>334</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.83</td>\n",
       "      <td>8.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0031</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>607.03</td>\n",
       "      <td>1488.44</td>\n",
       "      <td>1249.18</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>314.84</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8052.30</td>\n",
       "      <td>9.2231</td>\n",
       "      <td>0.02</td>\n",
       "      <td>364</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.42</td>\n",
       "      <td>14.7832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>42.0041</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>40.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.52</td>\n",
       "      <td>1354.48</td>\n",
       "      <td>1124.32</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>130.44</td>\n",
       "      <td>2387.89</td>\n",
       "      <td>8083.67</td>\n",
       "      <td>9.2986</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.99</td>\n",
       "      <td>6.4025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   10.0047    0.2501      20.0  489.05  604.13  1499.45  1309.95   \n",
       "1   1      2    0.0015    0.0003     100.0  518.67  642.13  1584.55  1403.96   \n",
       "2   1      3   34.9986    0.8401      60.0  449.44  555.42  1368.17  1122.49   \n",
       "3   1      4   20.0031    0.7005       0.0  491.19  607.03  1488.44  1249.18   \n",
       "4   1      5   42.0041    0.8405      40.0  445.00  549.52  1354.48  1124.32   \n",
       "\n",
       "      s5  ...     s12      s13      s14     s15   s16  s17   s18    s19  \\\n",
       "0  10.52  ...  372.15  2388.13  8120.83  8.6216  0.03  368  2319  100.0   \n",
       "1  14.62  ...  521.81  2388.15  8132.87  8.3907  0.03  391  2388  100.0   \n",
       "2   5.48  ...  183.26  2387.95  8063.84  9.3557  0.02  334  2223  100.0   \n",
       "3   9.35  ...  314.84  2388.07  8052.30  9.2231  0.02  364  2324  100.0   \n",
       "4   3.91  ...  130.44  2387.89  8083.67  9.2986  0.02  330  2212  100.0   \n",
       "\n",
       "     s20      s21  \n",
       "0  28.58  17.1735  \n",
       "1  38.99  23.3619  \n",
       "2  14.83   8.8555  \n",
       "3  24.42  14.7832  \n",
       "4  10.99   6.4025  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>last_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>109.500000</td>\n",
       "      <td>210.633028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>63.075352</td>\n",
       "      <td>43.595578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.250000</td>\n",
       "      <td>177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>109.500000</td>\n",
       "      <td>209.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>163.750000</td>\n",
       "      <td>236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>218.000000</td>\n",
       "      <td>357.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  last_cycle\n",
       "count  218.000000  218.000000\n",
       "mean   109.500000  210.633028\n",
       "std     63.075352   43.595578\n",
       "min      1.000000  128.000000\n",
       "25%     55.250000  177.000000\n",
       "50%    109.500000  209.500000\n",
       "75%    163.750000  236.000000\n",
       "max    218.000000  357.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_cycle = pd.DataFrame(df.groupby(\"id\")[\"cycle\"].max())\n",
    "df_max_cycle.reset_index(level=0 , inplace=True)\n",
    "df_max_cycle.columns = ['id', 'last_cycle']\n",
    "df_max_cycle.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>rul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0047</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>20.0</td>\n",
       "      <td>489.05</td>\n",
       "      <td>604.13</td>\n",
       "      <td>1499.45</td>\n",
       "      <td>1309.95</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>8120.83</td>\n",
       "      <td>8.6216</td>\n",
       "      <td>0.03</td>\n",
       "      <td>368</td>\n",
       "      <td>2319</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>17.1735</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.13</td>\n",
       "      <td>1584.55</td>\n",
       "      <td>1403.96</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8132.87</td>\n",
       "      <td>8.3907</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.3619</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.9986</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>60.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.42</td>\n",
       "      <td>1368.17</td>\n",
       "      <td>1122.49</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.95</td>\n",
       "      <td>8063.84</td>\n",
       "      <td>9.3557</td>\n",
       "      <td>0.02</td>\n",
       "      <td>334</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.83</td>\n",
       "      <td>8.8555</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0031</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>607.03</td>\n",
       "      <td>1488.44</td>\n",
       "      <td>1249.18</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8052.30</td>\n",
       "      <td>9.2231</td>\n",
       "      <td>0.02</td>\n",
       "      <td>364</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.42</td>\n",
       "      <td>14.7832</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>42.0041</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>40.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.52</td>\n",
       "      <td>1354.48</td>\n",
       "      <td>1124.32</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.89</td>\n",
       "      <td>8083.67</td>\n",
       "      <td>9.2986</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.99</td>\n",
       "      <td>6.4025</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   10.0047    0.2501      20.0  489.05  604.13  1499.45  1309.95   \n",
       "1   1      2    0.0015    0.0003     100.0  518.67  642.13  1584.55  1403.96   \n",
       "2   1      3   34.9986    0.8401      60.0  449.44  555.42  1368.17  1122.49   \n",
       "3   1      4   20.0031    0.7005       0.0  491.19  607.03  1488.44  1249.18   \n",
       "4   1      5   42.0041    0.8405      40.0  445.00  549.52  1354.48  1124.32   \n",
       "\n",
       "      s5  ...      s13      s14     s15   s16  s17   s18    s19    s20  \\\n",
       "0  10.52  ...  2388.13  8120.83  8.6216  0.03  368  2319  100.0  28.58   \n",
       "1  14.62  ...  2388.15  8132.87  8.3907  0.03  391  2388  100.0  38.99   \n",
       "2   5.48  ...  2387.95  8063.84  9.3557  0.02  334  2223  100.0  14.83   \n",
       "3   9.35  ...  2388.07  8052.30  9.2231  0.02  364  2324  100.0  24.42   \n",
       "4   3.91  ...  2387.89  8083.67  9.2986  0.02  330  2212  100.0  10.99   \n",
       "\n",
       "       s21  rul  \n",
       "0  17.1735  222  \n",
       "1  23.3619  221  \n",
       "2   8.8555  220  \n",
       "3  14.7832  219  \n",
       "4   6.4025  218  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_max_cycle, on=\"id\")\n",
    "df[\"rul\"] = df[\"last_cycle\"] - df[\"cycle\"]\n",
    "df.drop([\"last_cycle\"], axis=1 , inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45918, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap aggregating (Bagging)，從字面上來看，就是將資料裝成一個袋子一個袋子(Bag)，然後將每個袋子的結果結合在一起。\n",
    "\n",
    "演算法上，是將樣本重複抽樣(取後放回)，產生多個子資料集(Subsets)後，依序建立多個模型，最後再將所有模型的結果彙整在一起。如果是預測問題(Regression Problem)，那就把所有結果平均起來(Average)；如果是分類問題(Classification Problem)，那就用投票法(Voting)，判斷哪個類別出現最多次。如下圖所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image1](https://raw.githubusercontent.com/skydome20/R-Notes/master/src/R16/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型 Bias 跟 Variance 的議題上，Bagging 的手法有助於降低 variance。\n",
    "\n",
    "當每個子集資料在建模的時候，每個模型若獨自拿出來看，會發現都是一個「強模型」(較複雜的模型)，具有低 bias 跟高 variance 的特性；而如今，我們把不同高 variance 的模型結合在一起後，因為是平均(投票)的概念，其結果就會趨近於整體的平均表現，因此 variance 就不會太大。([為什麼說bagging是減少variance，而boosting是減少bias?](https://www.zhihu.com/question/26760839))\n",
    "\n",
    "這就是 Bagging 的概念：用抽樣資料建構的模型，會有好有壞，因此取平均(或投票法)來獲得較穩定(lower variance)的平均表現。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所謂的隨機森林，就是運用 Bagging + CART決策樹，也就是說Model-1 ~ Model-n全都都是用決策樹來建模，而這麼多棵的樹組合在一起，所以才稱為「森林」。\n",
    "\n",
    "要注意的是，隨機森林在抽樣過程中，不只是對 Row 進行抽樣，同時也會對 Column 抽樣，因此產生的子集資料，其實是對欄跟列抽樣後的結果。之後再針對這些子集資料，各自訓練一棵決策樹，形成隨機森林。\n",
    "\n",
    "事實上，在面對資料中有共線性(collinearity)跟類別不平衡(Class Imbalance Problem)，而這些問題會對預測結果造成不良影響時(若是探討對「變數解釋性」的影響，則需要用 Lasso 或 Stepwise 來解決)，隨機森林是倍受青睞的演算法。其概念應該不難理解：「對 Row 抽樣時，可以部份解決類別不平衡來影響預測的問題；對 Column 抽樣時，可以部份解決共線性來影響預測的問題」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "test_index = random.sample(list(range(1,219,1)), k=int(df[\"id\"].unique().shape[0]*0.3))\n",
    "train_index = []\n",
    "for i in range(1,219,1):\n",
    "    if i not in test_index:\n",
    "        train_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"id\"].isin(train_index)]\n",
    "test_df = df[df[\"id\"].isin(test_index)]\n",
    "x_train = train_df.drop([\"id\",\"rul\"], axis=1)\n",
    "y_train = train_df[\"rul\"]\n",
    "x_test = test_df.drop([\"id\",\"rul\"], axis=1)\n",
    "y_test = test_df[\"rul\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training: 159.100, MSE testing: 1215.392\n",
      "RMSE training: 12.613, RMSE testing: 34.862\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=1)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_test_predict = rf.predict(x_test)\n",
    "y_train_predict = rf.predict(x_train)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_predict)\n",
    "test_mse = mean_squared_error(y_test, y_test_predict)\n",
    "print('MSE training: %.3f, MSE testing: %.3f' % (\n",
    "      (train_mse), (test_mse)))\n",
    "print('RMSE training: %.3f, RMSE testing: %.3f' % (\n",
    "      (train_mse**0.5), (test_mse**0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_weights(model, weights, feature_names):\n",
    "    \n",
    "\n",
    "    (px, py) = (8, 10) \n",
    "    W = pd.DataFrame({'Weights':weights}, feature_names)\n",
    "    W_df = W.sort_values(by='Weights', ascending=True)\n",
    "    W_df.tail(10).plot(kind='barh', color='r', figsize=(px,py))\n",
    "    plt.xlabel(model)\n",
    "    plt.gca().legend_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_features_weights('Random Forest Regressor', rf.feature_importances_, x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest 是由許多的 Decision tree 構成，並且有可以透過畫圖的功能把每棵樹畫出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1791095845, splitter='best'),\n",
       " DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=2135392491, splitter='best'),\n",
       " DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=946286476, splitter='best'),\n",
       " DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1857819720, splitter='best'),\n",
       " DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=491263, splitter='best')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.estimators_[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡有一個建模中都會遇到的重要議題：「要決定多少決策樹？」(也就是n_estimators要設定多少？)\n",
    "\n",
    "而要決定隨機森林的最佳棵樹，可以透過 grid search 的方式去找尋超參數，並且比較 validation 的 mse，當然如果要避免超參數只是 overfitting validation data，可以利用 cross-validation 進一步的找尋能夠代表全部資料的超參數。\n",
    "\n",
    "而在 grid search 時超參數可以利用等比的方式來設定，由於超參數太過接近可能差異不大，找尋的時間需要非常的多，利用等比的方式可以找到更好的級數，找到之後可以在細調附近的超參數找尋到最好的數字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10.,   18.,   31.,   54.,   95.,  167.,  293.,  514.,  903.,\n",
       "       1585.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch = np.round(np.logspace(1,3.2,10),0)\n",
    "gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "18.0\n",
      "31.0\n",
      "54.0\n",
      "95.0\n",
      "167.0\n",
      "293.0\n",
      "514.0\n",
      "903.0\n",
      "1585.0\n"
     ]
    }
   ],
   "source": [
    "c_list = []\n",
    "train_f1 = []\n",
    "val_f1 = []\n",
    "for c in gridsearch:\n",
    "    rfc = RandomForestRegressor(n_estimators=int(c),random_state=0,n_jobs=-1).fit(x_train, y_train)\n",
    "    y_train_pred = rfc.predict(x_train)\n",
    "    y_val_pred = rfc.predict(x_test)\n",
    "    c_list.append(c)\n",
    "    train_f1.append(mean_squared_error(y_train, y_train_pred))\n",
    "    val_f1.append(mean_squared_error(y_test ,y_val_pred))\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1585.0</td>\n",
       "      <td>156.939060</td>\n",
       "      <td>1211.452400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>903.0</td>\n",
       "      <td>157.209114</td>\n",
       "      <td>1212.269016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>514.0</td>\n",
       "      <td>157.560705</td>\n",
       "      <td>1214.346612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>293.0</td>\n",
       "      <td>158.664820</td>\n",
       "      <td>1216.514825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167.0</td>\n",
       "      <td>160.712759</td>\n",
       "      <td>1220.229490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>164.720731</td>\n",
       "      <td>1225.514871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>169.704972</td>\n",
       "      <td>1240.400668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>179.674627</td>\n",
       "      <td>1256.306397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>195.770304</td>\n",
       "      <td>1279.089170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>227.403798</td>\n",
       "      <td>1337.647843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c   train_mse      val_mse\n",
       "9  1585.0  156.939060  1211.452400\n",
       "8   903.0  157.209114  1212.269016\n",
       "7   514.0  157.560705  1214.346612\n",
       "6   293.0  158.664820  1216.514825\n",
       "5   167.0  160.712759  1220.229490\n",
       "4    95.0  164.720731  1225.514871\n",
       "3    54.0  169.704972  1240.400668\n",
       "2    31.0  179.674627  1256.306397\n",
       "1    18.0  195.770304  1279.089170\n",
       "0    10.0  227.403798  1337.647843"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df = pd.DataFrame(c_list,columns=[\"c\"])\n",
    "grid_df[\"train_mse\"] = train_f1\n",
    "grid_df[\"val_mse\"] = val_f1\n",
    "grid_df.sort_values(by=\"val_mse\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1cbe0cd7be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(grid_df[\"c\"], grid_df[\"val_mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡發現 1585 棵樹最多數的時候 mse 越小，思考一下 bagging 的機制，其實越多樹很可能會有更低 mse，但是我們另外要觀察每個的超參數的差異性，可以發現到後面 mse的差距變得非常小，其實 293 棵樹就已經足夠了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在決定好 n_estimators 的數量後，另一個超參數 max_features 其實也可以去 Tune，這個參數代表每次抽樣時需要抽「多少個變數」的意思。\n",
    "\n",
    "並根據下面的結果與圖，得知每次抽樣時「抽10個變數」會是比較好的選擇："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = [5,10,15,20,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "c_list = []\n",
    "train_f1 = []\n",
    "val_f1 = []\n",
    "for c in gridsearch:\n",
    "    rfc = RandomForestRegressor(n_estimators=293,max_features=c,random_state=0,n_jobs=-1).fit(x_train, y_train)\n",
    "    y_train_pred = rfc.predict(x_train)\n",
    "    y_val_pred = rfc.predict(x_test)\n",
    "    c_list.append(c)\n",
    "    train_f1.append(mean_squared_error(y_train, y_train_pred))\n",
    "    val_f1.append(mean_squared_error(y_test ,y_val_pred))\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>155.305963</td>\n",
       "      <td>1198.760288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>155.198962</td>\n",
       "      <td>1199.528486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>156.705465</td>\n",
       "      <td>1201.888552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>157.076148</td>\n",
       "      <td>1209.597764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>158.664820</td>\n",
       "      <td>1216.514825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    c   train_mse      val_mse\n",
       "1  10  155.305963  1198.760288\n",
       "0   5  155.198962  1199.528486\n",
       "2  15  156.705465  1201.888552\n",
       "3  20  157.076148  1209.597764\n",
       "4  25  158.664820  1216.514825"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df = pd.DataFrame(c_list,columns=[\"c\"])\n",
    "grid_df[\"train_mse\"] = train_f1\n",
    "grid_df[\"val_mse\"] = val_f1\n",
    "grid_df.sort_values(by=\"val_mse\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1cba6198198>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(grid_df[\"c\"], grid_df[\"val_mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以跟一開始的模型比，會發現 mse 不管在 train / valid 都更小了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟 Bagging 使用多個「強模型」不同， Boosting 會強調使用上需要多個「弱模型」才可以。\n",
    "\n",
    "其概念用「三個臭皮匠，勝過一個諸葛亮」來形容最為貼切，也就是需要有多個非常弱的「臭皮匠」，而這些臭皮匠彼此是互補的。也就是說： M2 模型要能辦到 M1 模型所辦不到的， M3 要辦到 M2 所辦不到的……。\n",
    "\n",
    "會強調要「弱模型」，是因為模型本身如果「有點強」還不行。以最簡單的說法來說明：當模型都「有點強」時，彼此就會開始打架，造成有意見不合的狀況(這在人類社會中很常遇見吧XD)。\n",
    "\n",
    "以人類分工合作的概念來說，如果每個人只會一項技能，那只要好好專司自己的職責，便不會去插手其他人的事務；但如果今天大家都是碩士博士，那對於某個問題，便會有許多人都給意見，有時候反而會造成干擾。\n",
    "\n",
    "模型也是這樣的，今天 M1 M2 M3 如果太複雜(太強)，那彼此之間就會互相干擾，影響最後預測/分類結果；唯有彼此都是「弱模型」，才能好好專注在自己本身的預測/分類，然後再把彼此的成果結合一起，這就是 Boosting 的概念。(當然以計算效率的考量，這樣做也比較快)(In boosting, why are the learners “weak”?)\n",
    "\n",
    "在演算法中，要從資料中找 M1 M2 M3…的模型是有順序的，概念跟 Bagging完全不一樣：\n",
    "\n",
    "- 在 Bagging 時，我們是將資料做抽樣，因此獲得許多子集資料，並各別建模後，把結果平均/投票。\n",
    "\n",
    "- 在 Boosting 時，一開始先建一個簡單的模型 M1 ，此時會有預測錯誤的資料，把這些資料的權重加大，建 M2 模型，然後又會有預測錯的資料，再把資料的權重加大，建 M3 模型…\n",
    "\n",
    "演算法的概念如下圖所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image2](https://raw.githubusercontent.com/skydome20/R-Notes/master/src/R16/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型 Bias 跟 Variance 的議題上，Boosting 的手法有助於降低 bias。\n",
    "\n",
    "由於使用上是拿「弱模型」來用，這些弱模型其實是高 bias 跟 低 variance 的，並且每次迭代的時候，都會基於先前的模型上進行優化(用梯度下降法，決定這次模型建在哪裡能使損失函數下降最多)。既然是降低損失函數，表示過程中會越來越逼近實際值，換句話說，就是逐漸降低 bias 的意思。([为什么说bagging是减少variance，而boosting是减少bias?](https://www.zhihu.com/question/26760839))\n",
    "\n",
    "(由於使用的資料並非分類問題，因此難以用本資料進行 Boosting 的模擬實踐。接下來會介紹以 Boosting 為基準發展出的演算法，Gradient Boosting Machine。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine(XGboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所謂的 GBM 算是一種概念，是將梯度下降法(Gradient Descending)跟 Boosting 套件節合在一起的演算法，而後面的 Machine 指不特定的模型，只要能用梯度下降法找尋方向的模型都可以。\n",
    "\n",
    "目前市面上，如果使用 gbm 的套件，基本上都是 Tree-based 為主，也就是將數百個弱決策樹(CART)，跟梯度下降法和 Boosting 結合在一起。\n",
    "\n",
    "而 XGboost 又有些許不同，是本來的 Gradient Boosting Decision Tree(GBDT)的改良版本，細節處可以參考這篇文章：[机器学习算法中GBDT和XGBOOST的区别有哪些？](https://www.zhihu.com/question/41354392)。\n",
    "\n",
    "如果有在關注 Kaggle 的人，就會知道近年來 XGboost 被譽為是「Kaggle 神器」。原因無他，就是因為每年的得名隊伍，使用 XGboost 的團隊基幾乎大多數！(更多關於 XGboost 的介紹可以參考這篇：[机器学习算法中GBDT和XGBOOST的区别有哪些？](https://www.zhihu.com/question/41354392))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training: 1226.095, MSE testing: 1251.829\n",
      "RMSE training: 35.016, RMSE testing: 35.381\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingRegressor(random_state=1)\n",
    "\n",
    "gb.fit(x_train, y_train)\n",
    "\n",
    "y_test_predict = gb.predict(x_test)\n",
    "y_train_predict = gb.predict(x_train)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_predict)\n",
    "test_mse = mean_squared_error(y_test, y_test_predict)\n",
    "print('MSE training: %.3f, MSE testing: %.3f' % (\n",
    "      (train_mse), (test_mse)))\n",
    "print('RMSE training: %.3f, RMSE testing: %.3f' % (\n",
    "      (train_mse**0.5), (test_mse**0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=1, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_features_weights('Gradient Boosting Regressor', gb.feature_importances_, x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同樣利用 grid search 的放是找出最佳的決策樹數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10.,   18.,   31.,   54.,   95.,  167.,  293.,  514.,  903.,\n",
       "       1585.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch = np.round(np.logspace(1,3.2,10),0)\n",
    "gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "18.0\n",
      "31.0\n",
      "54.0\n",
      "95.0\n",
      "167.0\n",
      "293.0\n",
      "514.0\n",
      "903.0\n",
      "1585.0\n"
     ]
    }
   ],
   "source": [
    "c_list = []\n",
    "train_f1 = []\n",
    "val_f1 = []\n",
    "for c in gridsearch:\n",
    "    rfc = GradientBoostingRegressor(n_estimators=int(c),random_state=0).fit(x_train, y_train)\n",
    "    y_train_pred = rfc.predict(x_train)\n",
    "    y_val_pred = rfc.predict(x_test)\n",
    "    c_list.append(c)\n",
    "    train_f1.append(mean_squared_error(y_train, y_train_pred))\n",
    "    val_f1.append(mean_squared_error(y_test ,y_val_pred))\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>293.0</td>\n",
       "      <td>1104.230371</td>\n",
       "      <td>1222.994481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>167.0</td>\n",
       "      <td>1166.056601</td>\n",
       "      <td>1230.172922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>514.0</td>\n",
       "      <td>1038.983851</td>\n",
       "      <td>1231.327505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>903.0</td>\n",
       "      <td>954.376979</td>\n",
       "      <td>1239.865615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>1232.366040</td>\n",
       "      <td>1254.386394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1585.0</td>\n",
       "      <td>842.315363</td>\n",
       "      <td>1257.699477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1312.096148</td>\n",
       "      <td>1310.652554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1410.213841</td>\n",
       "      <td>1412.560886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1591.766452</td>\n",
       "      <td>1608.557503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1994.249709</td>\n",
       "      <td>2033.979133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c    train_mse      val_mse\n",
       "6   293.0  1104.230371  1222.994481\n",
       "5   167.0  1166.056601  1230.172922\n",
       "7   514.0  1038.983851  1231.327505\n",
       "8   903.0   954.376979  1239.865615\n",
       "4    95.0  1232.366040  1254.386394\n",
       "9  1585.0   842.315363  1257.699477\n",
       "3    54.0  1312.096148  1310.652554\n",
       "2    31.0  1410.213841  1412.560886\n",
       "1    18.0  1591.766452  1608.557503\n",
       "0    10.0  1994.249709  2033.979133"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df = pd.DataFrame(c_list,columns=[\"c\"])\n",
    "grid_df[\"train_mse\"] = train_f1\n",
    "grid_df[\"val_mse\"] = val_f1\n",
    "grid_df.sort_values(by=\"val_mse\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cb8d19dda0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(grid_df[\"c\"], grid_df[\"train_mse\"],label=\"train\")\n",
    "plt.plot(grid_df[\"c\"], grid_df[\"val_mse\"],label=\"valid\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以跟一開始的模型比，會發現 mse 不管在 train / valid 都更小了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般來說，Train 的表現會比 Validation 還要好，這時有兩種情況要思考：\n",
    "\n",
    "1.如果 Train 跟 Validation 相近，表示模型其實還可以訓練得更好(更複雜)，藉由提高 Train 的表現，觀察 Validation 是否有機會提升，因此可以調以下參數，以提高模型複雜度的概念進行：\n",
    "\n",
    "\n",
    "- max_depth 調高 1 單位 (最建議調這個)\n",
    "\n",
    "- max_features 調高比例 (調這個也不錯)\n",
    "\n",
    "- learning rate調低\n",
    "\n",
    "\n",
    "2.如果 Train 比 Validation 好太多，就表示有 ovrfitting的問題發生，這時候上面的參數就要反過來調，以降低模型複雜度的概念來進行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後要討論的 emsemble 技巧是 stacking，其概念很簡單：\n",
    "\n",
    "「在訓練多個模型、得到多個預測值/分類結果後，與其使用投票法(hard voting)或平均法(average)將這些結果整合(ensemble)起來，為何不多訓練一個模型來做這樣的整合呢？」\n",
    "\n",
    "下圖展現了 Stacking 的核心概念：\n",
    "\n",
    "「今天已經訓練好三個機器學習的模型，分別是 linear regression, support vector regression 跟 CART decision tree。當有一筆新資料需要預測時，會各自得到三個預測值(y1, y2, y3)，然後接下來作為最終模型(又稱 meta-model, blender, meta learner)的輸入值，得到最終預測結果(y.final)」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image3](https://raw.githubusercontent.com/skydome20/R-Notes/master/src/R16/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這跟傳統上的做法不太一樣，我們直覺上會把(y1, y2, y3)的結果直接拿來平均(預測問題)或投票法(分類問題)，得到最後的結果。\n",
    "\n",
    "不過 Stacking 採用另一個模型(blender)來取代這樣的概念。換句話說，也就是「把本來的預測結果再進一步做預測」的感覺。\n",
    "\n",
    "因此，Stacking 的演算法可以分成兩個階段，應該不難理解：\n",
    "\n",
    "1. Stacking：先訓練多個初始模型，其預測結果叫做 Meta-Data，作為最終模型(Meta-Model; Blender)的的輸入。\n",
    "\n",
    "2. Blending：最終模型會取得 Meta-Data ，整合出最後結果(Predicted Results)。\n",
    "\n",
    "不過當打算開始使用 Stacking 的技巧來建模，想必會立刻遇到瓶頸：「咦？那我要怎麼訓練初始模型跟最終模型？並得到所謂的 meta-data？」\n",
    "\n",
    "如果是訓練初始模型，想必大家都會，因為原始資料直接丟下去訓練就可以。\n",
    "\n",
    "不過現在卻有一個問題：「要怎麼訓練第二階段的最終模型 (Meta-Model) 呢？」\n",
    "\n",
    "感覺上，也需要有一筆訓練資料，才能訓練 Meta-Model…事實上，這樣想是對的，只不過這時的訓練資料，又稱Meta-X，會從初始模型的預測結果而來…只是怎麼來呢？\n",
    "\n",
    "所以讓我們先看初始模型的訓練，跟取得 Meta-Data(Meta-X 跟 Meta-Y) 吧！\n",
    "\n",
    "基本上，在訓練初始模型取得 Meta-Data 時，會搭配類似 K-folds 的技巧，將訓練資料切割成數個子集資料(Subsets)。\n",
    "\n",
    "在上一張圖中我們有三個模型，這裡舉第一個模型(Linear Regression 線性迴歸)為例，如下圖(大圖下載)："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image4](https://raw.githubusercontent.com/skydome20/R-Notes/master/src/R16/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假設將訓練資料(Train Data)分成三個子集資料(3-folds)，當然不一定要三個，依情況而定。\n",
    "\n",
    "因此，從訓練資料(Train Data)中分割而出資料子集，綠色部分會用來訓練模型，紅色部分會拿來預測並取得 Predict_X。\n",
    "\n",
    "由圖中可以得知，概念就是把本來的(Train Data)，經由預測後，全轉換成 Predict_X 的狀態，這時又被稱作 Meta-X，會當成最終模型(Meta-Model)的訓練資料。\n",
    "\n",
    "另外，我們手中還有原始的測試資料(Test Data)，丟入模型預測後會得到 Predict (紫色部分)。\n",
    "\n",
    "但由於我們一開始把資料分成三份，所以會有三個模型，也會得到三組測試資料的預測結果，這時就直接用平均法(連續問題)/投票法(分類問題)，將這三組預測結果整合起來，變成 Predict_Y 的狀態，又被稱作 Meta-Y，並丟給最終模型(Meta-Model)來預測。\n",
    "\n",
    "換句話說，當擁有多個模型時，我們必須各自取得每個模型的 Meta-X 跟 Meta-Y，來作為最終模型(Meta-Model)的訓練及測試資料集。\n",
    "\n",
    "因此，整個 Stacking 的概念可以用下圖表示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image5](https://raw.githubusercontent.com/skydome20/R-Notes/master/src/R16/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當然，上面示範兩階段的狀況而已。實際上在 Kaggle 比賽中，很常看見發展成三、四階段的 Stacking 模型。\n",
    "\n",
    "例如，在簡言中提及的得獎隊伍，就是使用多層階段的 Stacking 模型(同時搭配 Feature Engineering 的技巧)。\n",
    "\n",
    "下一小節，會用 Python 實踐 Stacking 的概念，使用的模型會跟上面的圖例和流程一樣，可以程式碼及概念相互比對學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code for Stacking Implementg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一階段 (Stacking)\n",
    "\n",
    "一開始，我們把訓練資料 Train 分成三份(3-folds)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_index)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 69,\n",
       " 23,\n",
       " 197,\n",
       " 105,\n",
       " 217,\n",
       " 28,\n",
       " 10,\n",
       " 98,\n",
       " 138,\n",
       " 144,\n",
       " 86,\n",
       " 88,\n",
       " 218,\n",
       " 41,\n",
       " 35,\n",
       " 87,\n",
       " 208,\n",
       " 207,\n",
       " 180,\n",
       " 63,\n",
       " 42,\n",
       " 1,\n",
       " 112,\n",
       " 216,\n",
       " 153,\n",
       " 97,\n",
       " 18,\n",
       " 2,\n",
       " 81,\n",
       " 188,\n",
       " 115]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index[0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"id\"].isin(train_index)]\n",
    "test_df = df[df[\"id\"].isin(test_index[:32])]\n",
    "stack_df = df[df[\"id\"].isin(test_index[32:])]\n",
    "x_train = train_df.drop([\"id\",\"rul\"], axis=1)\n",
    "y_train = train_df[\"rul\"]\n",
    "x_stack = stack_df.drop([\"id\",\"rul\"], axis=1)\n",
    "y_stack = stack_df[\"rul\"]\n",
    "x_test = test_df.drop([\"id\",\"rul\"], axis=1)\n",
    "y_test = test_df[\"rul\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分別建立三個模型\n",
    "\n",
    "分別是linear regression及前面調好超參數的兩個模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=293,max_features=10,random_state=0,n_jobs=-1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=293,random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分別利用三個模型去預測 stacking 的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = rf.predict(x_stack)\n",
    "clf2 = gb.predict(x_stack)\n",
    "clf3 = lr.predict(x_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = []\n",
    "for i in range(len(y_stack)):\n",
    "    stack_train.append([clf1[i], clf2[i], clf3[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[208.2320819112628, 207.70609038416512, 183.93365530198207],\n",
       " [208.84641638225256, 221.43373617050187, 192.17166646255646],\n",
       " [203.3071672354949, 214.6870453540401, 188.3417806282523],\n",
       " [198.90102389078498, 202.5311784981612, 181.30975120700896],\n",
       " [208.71672354948805, 214.63871340789336, 194.64430417475523],\n",
       " [190.2764505119454, 198.92456323996439, 183.27085765224183],\n",
       " [196.03754266211604, 202.527846559721, 197.81401016417658],\n",
       " [213.66894197952217, 196.4637679512504, 175.51769712939858],\n",
       " [203.84982935153585, 206.1602213359495, 188.75079401035327],\n",
       " [195.47440273037543, 204.5127659727982, 186.51742455735803]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練 stacking model，把三個模型預測出來的東西當作 X 來建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = LinearRegression().fit(stack_train, y_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39789625, 0.42389407, 0.25670426])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從係數可以看出不同模型的重要程度，其中 gradient boosting 是最重要的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用預測 stacking model 做預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(x_test):\n",
    "    clf1_test = rf.predict(x_test)\n",
    "    clf2_test = gb.predict(x_test)\n",
    "    clf3_test = lr.predict(x_test)\n",
    "    stack_test = []\n",
    "    for i in range(len(x_test)):\n",
    "        stack_test.append([clf1_test[i], clf2_test[i], clf3_test[i]])\n",
    "    ensemble_predict = stack_model.predict(stack_test)\n",
    "    return ensemble_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ensemble_pred = ensemble_predict(x_train)\n",
    "y_test_ensemble_pred = ensemble_predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training: 692.721, MSE testing: 1340.558\n",
      "RMSE training: 26.320, RMSE testing: 36.614\n"
     ]
    }
   ],
   "source": [
    "train_mse = mean_squared_error(y_train, y_train_ensemble_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_ensemble_pred)\n",
    "\n",
    "print('MSE training: %.3f, MSE testing: %.3f' % (\n",
    "      (train_mse), (test_mse)))\n",
    "print('RMSE training: %.3f, RMSE testing: %.3f' % (\n",
    "      (train_mse**0.5), (test_mse**0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 總結"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "關於 Ensemble Learning，其實牽扯的層面相當廣泛，實在很難在短短一篇文章中，便將所有細節及該考量的議題書寫出來，因此只能在本文中提及我認為較重要的地方。\n",
    "\n",
    "若真的想要好好了解這個技巧，並且知道背後的數學公式以幾何含意，歡迎聆聽[台大李宏毅老師的教學影片(Ensemble)](https://www.youtube.com/watch?v=tH9FH1DH5n0&ab_channel=Hung-yiLee) ，講解得非常完整，相當值得好好花一個半小時來學習；\n",
    "\n",
    "或是閱讀南京大学周志华老师的文章 [Ensemble methods: foundations and algorithms](http://www2.islab.ntua.gr/attachments/article/86/Ensemble%20methods%20-%20Zhou.pdf)，裡面對各種 Ensemble Models 有很好的詳解，以及優缺點討論。\n",
    "\n",
    "另外，這本 [Hands-OnMachine Learningwith Scikit-Learn& TensorFlow (p.181 ~ p.202)](http://www.deeplearningitalia.com/wp-content/uploads/2017/12/Dropbox_Hands-On-Machine-Learning-with-Scikit-Learn-and-Tensorflow-Aurelien-Geron.pdf) 也提供了很完整的介紹跟 python 程式碼。\n",
    "\n",
    "Ensemble Learning 雖然在預測上的效果很好，是傳統模型無法比擬的。不過當大家都追求「高預測表現」時，或許有時候需要慢下來，試著重新回到最基本的模型(線性迴歸、決策樹)，並探討資料中變數的深層涵義，思考資料跟現實中如何互相影響、對應，並做出未來的決策方向……或許，這樣才能真正解決存在於現實中的問題(痛點)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. [R筆記 – (16) Ensemble Learning(集成學習)](https://rpubs.com/skydome20/R-Note16-Ensemble_Learning)\n",
    "\n",
    "1. [为什么说bagging是减少variance，而boosting是减少bias?](https://www.zhihu.com/question/26760839)\n",
    "\n",
    "2. [ML Lecture 22: Ensemble](https://www.youtube.com/watch?v=tH9FH1DH5n0&ab_channel=Hung-yiLee)\n",
    "\n",
    "3. [机器学习算法中 GBDT 和 XGBOOST 的区别有哪些？](https://www.zhihu.com/question/41354392)\n",
    "\n",
    "4. [集成学习总结 & Stacking方法详解](https://blog.csdn.net/willduan1/article/details/73618677)\n",
    "\n",
    "5. [[ML筆記] Ensemble - Bagging, Boosting & Stacking](http://violin-tao.blogspot.com/2018/01/ml-ensemble.html)\n",
    "\n",
    "6. [从Boosting到Stacking，概览集成学习的方法与性能](https://www.jiqizhixin.com/articles/2017-08-28-3)\n",
    "\n",
    "7. [Random Forest和Gradient Tree Boosting参数详解](https://www.cnblogs.com/jasonfreak/p/5720137.html)\n",
    "\n",
    "8. [In boosting, why are the learners “weak”?](https://stats.stackexchange.com/questions/23388/in-boosting-why-are-the-learners-weak)\n",
    "\n",
    "9. [Learn Kaggle techniques from Kaggle #1, Owen Zhang](https://www.youtube.com/watch?v=LgLcfZjNF44&feature=youtu.be&t=15m7s&ab_channel=NYCDataScienceAcademy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
