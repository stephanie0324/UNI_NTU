{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 邏輯斯迴歸\n",
    "## 目錄\n",
    "---\n",
    "1. Introduction\n",
    "2. 資料預處理\n",
    "3. 建置模型\n",
    "4. 模型評估\n",
    "5. 參考資源\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "邏輯斯迴歸模型是在機器學習中常見的分類模型，專門用來處理類別型資料，而其中又分為 Binary Classification 以及 Multi-class Classification\n",
    "\n",
    "於原理上，可以發現邏輯斯迴歸模型與線性迴歸模型很像，都是要找到一條線來進行預測。然而，使用上的意義卻是完全不同，對於邏輯斯回歸而言，我們找到的這條線是想要將資料點在一個空間中能夠切出不同分類的結果，透過最大似然估計的方式預估這條線的係數。\n",
    "\n",
    "其中，羅吉斯迴歸用到的 logit 函數，也被稱作 Sigmoid 函數，在深度學習領域常被拿來使用或是比較，可以將任意輸入值輸出成0到1之間的函數\n",
    "\n",
    "sigmoid: $\\sigma(x)= \\frac{e^{x}}{1+e^{x}} = \\frac{1}{1+e^{-x}}$\n",
    "\n",
    "寫過來我們的機率函數變成\n",
    "$p(x) = \\frac{1}{1 + e^{-(\\beta_0+\\beta_1 x_1+\\beta_2 x_2+ \\ldots +\\beta_p x_p)}} = \\sigma(\\beta_0+\\beta_1 x_1+\\beta_2 x_2+ \\ldots +\\beta_p x_p)$\n",
    "\n",
    "轉換為邏輯斯回歸的形式 $logit(p) = log(odds) = log(\\frac{p(x)}{1-p(x)}) = \\beta_0+\\beta_1 x_1+\\beta_2 x_2 + \\ldots +\\beta_p x_p$\n",
    "\n",
    "羅吉斯回歸方程式將類別型態的反應變數轉換為事件的 log odds 值，也就是 $log(\\frac{P_i}{1 - P_i})$\n",
    "⟯，來預測與自變數($X_1$ ~ $X_n$) 的線性關係，接下來邏輯斯迴歸模型將會用最大概似估計法求解，並且找出最佳的 Beta 估計值，通常這個步驟就會交由我們偉大的 sklearn 來幫我們完成！\n",
    "\n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們要使用 sklearn 中的一個資料集 - breast_cancer，用來示範邏輯斯回歸模型的使用，該資料集用不同的照片轉數據的特徵來判斷該病患是否罹患乳癌（良性：benign（1），惡性：malignant (0)），該分析的資料屬於 Binary Classification。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n",
    "y = pd.DataFrame(breast_cancer.target, columns = ['target'])\n",
    "data = pd.concat([x, y], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "該資料中有 569 筆資料，且當中有 357 筆良性的資料以及 212 筆惡性的資料\n",
    "從資料敘述來看，可以發現資料間彼此的尺度差異相當大，因此可以先進行標準化的預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查遺漏值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料預處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了避免後續的預測及避免模型 underfitting/overfitting，我們將資料切分成訓練集與測試集。另一方面，為了不使資料維度大小影響預測結果，我們也將資料進行標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_std = scaler.transform(x_train)\n",
    "x_test_std = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 建置模型\n",
    "我們使用 sklearn 套件中的 logistic regression 演算法進行分類器訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 sklearn 中的 logistic regression 預測時，參數可以選擇是否使用 l1、l2、elasticnet 作為 penalty，再將我們的 training data 作為 fitting 的資料，接著即可訓練出我們的分類器，並用 clf 變數來保存已經 train 好的分類器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2').fit(x_train_std, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用已訓練好的分類器我們可以傳入 test data，並且可以回傳分類器對於每筆預測資料的判斷是否為良性的機率為多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.14327437e-01, 8.85672563e-01],\n",
       "       [9.99990961e-01, 9.03924655e-06],\n",
       "       [9.96901657e-01, 3.09834256e-03],\n",
       "       [5.10962742e-04, 9.99489037e-01],\n",
       "       [6.08832659e-05, 9.99939117e-01],\n",
       "       [1.00000000e+00, 9.60957939e-11],\n",
       "       [9.99999998e-01, 1.57079869e-09],\n",
       "       [9.64865916e-01, 3.51340843e-02],\n",
       "       [3.80706222e-01, 6.19293778e-01],\n",
       "       [7.64631525e-04, 9.99235368e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = clf.predict(x_test_std)\n",
    "clf.predict_proba(x_test_std)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們可以根據模型的結果來試著解釋模型怎麼判斷結果，簡單的思考：\n",
    "- 若係數為正，代表該 feature 對於模型判斷是否為某 class 有正面的影響\n",
    "- 若係數為負，則相反\n",
    "- 如果將係數取絕對值，絕對值越大，代表影響力越深\n",
    "\n",
    "我們可以看一下這個模型的係數，從絕對值大小來看的話，可以發現一些比較重要的係數：\n",
    "- worst fractal dimension\n",
    "- worst texture\n",
    "- radius error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius : -0.42789615386484475\n",
      "mean texture : -0.3939134277206189\n",
      "mean perimeter : -0.38955025196393456\n",
      "mean area : -0.46431617825015864\n",
      "mean smoothness : -0.06675416301240383\n",
      "mean compactness : 0.542106247117378\n",
      "mean concavity : -0.7967712717964246\n",
      "mean concave points : -1.1170207006060748\n",
      "mean symmetry : 0.2357125658089102\n",
      "mean fractal dimension : 0.07670116596628906\n",
      "radius error : -1.2711472154818995\n",
      "texture error : 0.18863977214458347\n",
      "perimeter error : -0.609365807382784\n",
      "area error : -0.9097997916544216\n",
      "smoothness error : -0.31246106295015347\n",
      "compactness error : 0.6859722927398417\n",
      "concavity error : 0.1808153111531741\n",
      "concave points error : -0.31769168455369595\n",
      "symmetry error : 0.499979759346927\n",
      "fractal dimension error : 0.6134054116708008\n",
      "worst radius : -0.8786104347308604\n",
      "worst texture : -1.3421882977984925\n",
      "worst perimeter : -0.5875570664037005\n",
      "worst area : -0.8465592373884729\n",
      "worst smoothness : -0.5499445856841431\n",
      "worst compactness : 0.00520705018834633\n",
      "worst concavity : -0.9457137512065071\n",
      "worst concave points : -0.7734362141127026\n",
      "worst symmetry : -1.2085312550964924\n",
      "worst fractal dimension : -0.1541604011999584\n"
     ]
    }
   ],
   "source": [
    "coef = clf.coef_[0]\n",
    "for i in range(len(data.columns[:-1])):\n",
    "     print(data.columns[i], \":\", coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型評估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 confusion matrix 、accuracy 、 recall 、 f1-score 來評估訓練好的分類器好壞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(\"Accuracy score:\", clf.score(x_test_std, y_test))\n",
    "matric = confusion_matrix(y_test,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(matric,square=True,annot=True,cbar=False)\n",
    "plt.xlabel(\"predict value\")\n",
    "plt.ylabel(\"true value\")\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          良性       0.97      0.99      0.98        71\n",
      "          惡性       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"report:\\n\",classification_report(y_test,predict,labels=[1,0],target_names=[\"良性\",\"惡性\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，對於這種分類模型，也可以使用 ROC curve 以及 AUC 來評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, plot_roc_curve\n",
    "plot_roc_curve(clf, x_test_std, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "綜合不同模型的衡量指標來看，可以發現使用邏輯斯回歸的成效不錯，對於乳癌的預測具有良好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 參考資源\n",
    "- RPubs Logistic Regression Ginger Zhan\n",
    "https://rpubs.com/ginger_zhan/logistic_regression\n",
    "- sklearn logisticRegreesion\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- 機器學習-邏輯回歸(Logistic Regression)\n",
    "http://www.taroballz.com/2018/07/18/ML_LogisticRegression/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
